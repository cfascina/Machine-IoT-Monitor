{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c6950-525d-4e54-a25e-13e9d6818c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import findspark\n",
    "import os\n",
    "import pyspark\n",
    "import time\n",
    "\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import col, from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = config['LOCAL']['TOPIC']\n",
    "SERVER = config['LOCAL']['SERVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172de34-9787-4f22-b1a7-8e9bb3b7cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f1973-363c-4112-8440-62fca2410984",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().set('spark.driver.host','127.0.0.1')\n",
    "sc = pyspark.SparkContext(master='local', appName='Machine-IoT-Monitor',conf=conf)\n",
    "spark = SparkSession.builder.appName('Machine-IoT-Monitor').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark.SparkContext(app='MachineMonitor').setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb79367",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('id_machine', StringType(), True), \n",
    "    StructField('temperature', IntegerType(), True),\n",
    "    StructField('rpm', IntegerType(), True),\n",
    "    StructField('timestamp', StringType(), True) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0de89c-e700-4754-9175-d95777b95a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format('kafka') \\\n",
    "    .option('kafka.bootstrap.servers', SERVER) \\\n",
    "    .option('subscribe', TOPIC) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a505e1-6004-48ab-8275-0cdb96de583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.selectExpr('CAST(value AS STRING)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import col, from_json\n",
    "# display(\n",
    "#   df.select(col('value'), from_json(col('value'), topic_schema, {\"mode\" : \"PERMISSIVE\"}))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f204e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    'jsonData', \n",
    "    from_json(col('value'), schema)\n",
    ").select('jsonData.*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3161f325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759be47e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f064e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_streaming = df.groupby('id_machine').mean('temperature', 'rpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_streaming = \\\n",
    "#     df_streaming.select(\n",
    "#         col('id_machine'),\n",
    "#         col('avg(temperature)').alias('avg_temperature'),\n",
    "#         col('avg(rpm)').alias('avg_rpm')\n",
    "#     )\n",
    "\n",
    "df_streaming = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_streaming.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe7c1b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_table = f\"machine_data_{time.strftime('%H%M%S', time.localtime())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc17229",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = df_streaming \\\n",
    "    .writeStream \\\n",
    "    .queryName(temp_table) \\\n",
    "    .outputMode('complete') \\\n",
    "    .format('memory') \\\n",
    "    .start()\n",
    "\n",
    "# streaming = df \\\n",
    "#     .writeStream \\\n",
    "#     .queryName(temp_table) \\\n",
    "#     .outputMode('append') \\\n",
    "#     .format('memory') \\\n",
    "#     .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streams ativados\n",
    "# spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(f\"SELECT id_machine, avg_temperature, avg_rpm from {temp_table}\").show()\n",
    "spark.sql(f\"SELECT * from {temp_table}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec7bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    # spark.sql(f\"SELECT id_machine, avg_temperature, avg_rpm from {temp_table}\").show()\n",
    "    spark.sql(f\"SELECT id_machine, temperature, rpm, timestamp from {temp_table}\").show()\n",
    "    time.sleep(15)\n",
    "    \n",
    "streaming.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
